{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# mnist data load\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_shape\n",
    "print(train_images.shape)\n",
    "print(len(train_labels))\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_shape\n",
    "print(test_images.shape)\n",
    "print(len(test_labels))\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compile\n",
    "network.compile(optimizer = 'rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n",
      "(60000, 784)\n",
      "(10000, 28, 28)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# data loader\n",
    "print(train_images.shape)\n",
    "train_images_ = train_images.reshape( (60000, 28 * 28 ))\n",
    "print(train_images_.shape)\n",
    "train_images_ = train_images_.astype('float32') / 255\n",
    "print(train_images_.shape)\n",
    "\n",
    "print(test_images.shape)\n",
    "test_images_ = test_images.reshape( (10000, 28 * 28 ))\n",
    "print(test_images_.shape)\n",
    "test_images_ = test_images_.astype('float32') / 255\n",
    "print(test_images_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label loader\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2566 - accuracy: 0.9260\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1036 - accuracy: 0.9686\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0677 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0497 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0370 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a480c24bb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting\n",
    "network.fit(\n",
    "    x = train_images_,\n",
    "    y = train_labels,\n",
    "    epochs = 5,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 747us/step - loss: 0.0622 - accuracy: 0.9810\n",
      "test_acc > : 0.9810000061988831\n"
     ]
    }
   ],
   "source": [
    "# test evaluation\n",
    "test_loss, test_acc = network.evaluate(test_images_, test_labels)\n",
    "print('test_acc > :', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망을 위한 데이터 표현\n",
    "\n",
    "        Tensor == 데이터를 위한 컨테이너"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 스칼라 0D Tensor\n",
    "# 하나의 숫자만 담고 있는 tensor == scalar ( numpy > float32, float64 ) tensor의 축 개수는 rank \n",
    "\n",
    "import numpy as np\n",
    "x = np.array(12) # scalar tensor\n",
    "print(x)\n",
    "print(x.ndim) # number of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  3  6 14  7]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 벡터 1D Tensor\n",
    "# 하나의 축을 가진 tensor\n",
    "\n",
    "x = np.array( [12, 3, 6, 14, 7]) # 5개 원소 == 5차원 벡터.\n",
    "print(x)\n",
    "print(x.ndim)\n",
    "\n",
    "# 5D 벡터는 하나의 축을 따라 5개의 차원을 가진 것. 5D tensor는 5개의 축을 가진 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 행렬 metrix 2D Tensor\n",
    "\n",
    "x = np.array(\n",
    "    [[5,78,2,34,0], # 행 > 1행 : [5,78,2,34,0]\n",
    "     [6,79,3,35,1],\n",
    "     [7,80,4,36,2]]\n",
    ")\n",
    "     # 열 > 1열 : [5,6,7]\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 3D Tensor & 고차원 Tensor\n",
    "x = np.array(\n",
    "    [[[5,78,2,34,0],\n",
    "      [6,79,3,35,1],\n",
    "      [7,80,4,36,2]],\n",
    "     [[5,78,2,34,0],\n",
    "      [6,79,3,35,1],\n",
    "      [7,80,4,36,2]],\n",
    "     [[5,78,2,34,0],\n",
    "      [6,79,3,35,1],\n",
    "      [7,80,4,36,2]]]\n",
    ")\n",
    "\n",
    "print(x.ndim)\n",
    "\n",
    "# 3D tensor를 하나의 배열로 합치면 4D 텐서를 만드는 식으로 이어짐. 동영상 데이터를 다룰 경우에는 5D 텐서까지 가기도 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "축의 개수 (rank) :  np.ndim 에서 확인 가능\n",
    "크기 (shape) : Tensor의 각 축을 따라 얼마나 많은 차원이 있는지를 나타내느 파이썬의 tuple\n",
    "               위의 3D Tensor의 크기는 (3,3,5) , 2D Tensor의 크기는 (3,5), 1D 벡터의 크기는 (5,), Scalar의 크기는 ()\n",
    "데이터 타입 : numpy에서는 dtype에 저장. ( float32, uint8, float64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# 축 확인\n",
    "print(train_images.ndim)\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)\n",
    "\n",
    "# 8비트 정수형 3D 텐서\n",
    "# 28 x 28 크기의 정수 행렬 6만개가 있는 배열.\n",
    "# 각 행렬은 하나의 흑백 이미지. 행렬의 각 원소는 0~255 사이값을 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3D Tensor에서 5번째 샘플 확인\n",
    "digit = train_images[4]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# numpy로 Tensor 조정\n",
    "my_slice = train_images[10:100] # 11번째 ~ 101번째까지\n",
    "print(my_slice.shape)\n",
    "\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(my_slice.shape)\n",
    "\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 14, 14)\n",
      "(60000, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# 오른쪽 하단 14x14 픽셀 선택시\n",
    "my_slice = train_images[:, 14:, 14:]\n",
    "print(my_slice.shape)\n",
    "\n",
    "# 음수 index\n",
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 데이터\n",
    "# 일반적으로 딥러닝에서 사용하는 모든 데이터 Tensor의 첫 번째 축 == 샘플 축\n",
    "# MNIST [0] == 숫자 이미지\n",
    "# 딥러닝 모델은 한 번에 전체 데이터셋을 처리하지 않는다. 대신 데이터를 batch로 나눔.\n",
    "\n",
    "batch_size = 128\n",
    "batch_1 = train_images[:128]\n",
    "batch_2 = train_images[128:256]\n",
    "# batch_n = train_images[128 * n : 128 * (n+1)]\n",
    "\n",
    "# 배치 데이터를 다룰 때는 첫 번째 축을 배치 축 또는 배치 차원이라고 부름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor 실제사례\n",
    "# 벡터 데이터 > (samples, features) 크기의 2D\n",
    "# 시계열 데이터 또는 시퀀스 데이터 > (samples, timesteps, features) 크기의 3D 텐서\n",
    "# 이미지 > (samples, height, width, channels) 또는 (samples, channels, height, width) 크기의 4D 텐서\n",
    "# 동영상 > (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 데이터\n",
    "# 대부분의 경우 해당. 데이터셋에서는 하나의 데이터 포인트가 벡터로 인코딩 될 수 있으므로 배치 데이터는 2D 텐서로 인코딩.\n",
    "# 첫 번째 축은 샘플 축, 두 번째 축은 특성 축\n",
    "# 사람의 나이, 우편 번호, 소득으로 구성된 인구 통계 데이터. 각 사람은 3개의 값을 가진 벡터로 구성, 10만 명이 포함된 전체 데이터셋은 (100000,3) 크기의 텐서에 저장될 수 있다.\n",
    "# (공통 단어 2만 개로 만든 사전에서) 각 단어가 등장한 횟수로 표현된 텍스트 문서 데이터셋. 각 문서는 2만 개의 원소(사전에 있는 단어마다 하나의 원소에 대응합니다.) 를 가진 벡터로 인코딩 될 수 있습니다.\n",
    "# 500개의 문서로 이루어진 전체 데이터셋은 (500, 20000) 크기의 텐소로 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 또는 시퀀스 데이터\n",
    "# 데이터에서 시간이 중요할 때는 시간 축을 포함하여 3D텐서로 저장됨.\n",
    "# 각 샘플은 벡터의 시퀀스로 인코딩되므로 배치 데이터는 3D 텐서로 인코딩치\n",
    "# 관례적으로 시간 축은 항상 두 번째 축( 인덱스 ==1 ). \n",
    "# 주식 가격 데이터 셋 >  1분 마다 현재 주식 가격, 지난 1분 동안에 최고 가격과 최소 가격을 저장. 1분마다 데이터는 3D 벡터로 인코딩되고 하루 동안의 거래는 (390,3) 크기의 2D 텐서로 인코딩됩니다. (하루 거래 390분)\n",
    "# 250일치의 데이터는 (250, 390, 3) 크기의 3D 텐서로 저장될 수 있음. 여기에서 1일치 데이터가 하나의 샘플\n",
    "# 트윗 데이터셋 >  각 트윗은 128개의 알파벳으로 구성된 280개의 문자 시퀀스. 여기에서는 각 문자가 128개의 크기인 이진 벡터로 인코딩 (해당 문자의 인덱스만 1, 나머지 0). 그러면 각 트윗은 (280,128) 크기의 2D \n",
    "# 텐서로 인코딩 될 수 있음. 100만 개의 트윗으로 구성된 데이터셋은 (1000000, 280,128) 크기의 텐서."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지는 전형적으로 높이, 너비, 컬러 채널의 3차원으로 이루어짐. MNIST 숫자처럼 흑백 이미지는 하나의 컬러 채널만을 가지고 있어 2D 텐서로 저장. 관례상 이미지 텐서는 3D로 저장.\n",
    "# 흑백 이미지의 경우 컬러 채널의 차원 크기는 1. 256x256 크기의 흑백 이미지에 대한 128개의 배치는 (128, 256,256, 1) 크기의 텐서에 저장될 수 있음.\n",
    "# 컬러 이미지에 대한 128개의 배치라면 (128, 256, 256, 3) 크기의 텐서에 저장.\n",
    "\n",
    "# 이미지 텐서의 크기를 지정하는 방식은 두 가지.\n",
    "\n",
    "# (Tensorflow) 채널 마지막 방식    //    (씨아노) 채널 우선 방식.\n",
    "# 구글의 tensorflow 머신 러닝 프레임워크는 (samples, height, width, color_depth)처럼 컬러 채널의 깊이를 끝에 놓는다.\n",
    "# 씨아노는 (samples, color_depth, height, width)처럼 컬러 채널의 깊이를 배치 축 바로 뒤에 놓음.\n",
    "# 씨아노 방식을 사용하면 앞선 예제 > (128, 1, 256, 256) 그리고 (128, 3, 256, 256)\n",
    "# 케라스는 두개 다 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비디오 데이터\n",
    "# 비디오 데이터는 현실에서 5D 텐서가 필요한 몇 안되는 데이터 중 하나. 하나의 비디오는 프레임의 연속, 각 프레임은 하나의 컬러 이미지.\n",
    "# 프레임이 (height, width, color_depth) 의 3D Tensor로 저장될 수 있기 때문에 프레인의 연속은 (frames, height, width, color_depth) 4D Tensor 로 저장\n",
    "# 여러 비디오의 배치는 (samples, frames, height, width, color_depth) 로 5D Tensor.\n",
    " \n",
    "# 예를 들어 60초짜리 144x256 유튜브 비디오 클립을 초당 4frame 으로 샘플링 하면 240 프레임.\n",
    "#  이런 비디오 클립을 4개 가진 배치는 (4, 240,144,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망의 톱니바퀴\n",
    "\n",
    "# Dense 층\n",
    "\"\"\"Keras.layers.Dense(512, activation='relu')\"\"\"\n",
    "\n",
    "# 2D 텐서를 입력으로 받고 입력 텐서의 새로운 표현인 또 다른 2D 텐서를 반환하는 함수 (w는 2D텐서, b는 벡터)\n",
    "\"\"\"output = relu(dot(w, input) +b)\"\"\"\n",
    "\n",
    "# 자세하게\n",
    "# 입력 텐서와 텐서 w 사이의 점곱(dot), 점곱의 결과인 2D 텐서와 벡터 b 사이의 덧셈(+), 마지막으로 relu 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원소별 연산\n",
    "# relu 함수와 덧셈은 원소별 연산.\n",
    "\n",
    "# 단순 원소별 연산\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # x s는 2D 넘파이 배열\n",
    "    # assert : 가정설정문. assert 뒤의 조건이 True가 아니면 AssertError를 발생시킨다.\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j],0)\n",
    "    return x\n",
    "\n",
    "# 덧셈 - 동일한 2D 텐서만 지원\n",
    "def naive_add(x,y):\n",
    "    assert len(x.shape) == 2 # x,y 2D 넘파이 배열\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "    return x\n",
    "\n",
    "# 같은 원리로 원소별 곱셈, 뺄샘 등을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 원소별 연산\n",
    "# import numpy as np\n",
    "# z = x + y # 원소별 덧셈\n",
    "# z = np.maximum(z, 0.) # 월소별 Relu 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브로드캐스팅\n",
    "# 모호하지 않고 실행 가능하다면 작은 텐서가 큰 텐서의 크기에 맞추어 브로드캐스팅이 됨.\n",
    "# 1) 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가됨. ( 브로드캐스팅 축 )\n",
    "# 2) 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 의 크기는 (32, 10), y 의 크기는 (10,) 일 때,\n",
    "# y에 비어있는 첫 번째 축을 추가하여 (1, 10) 으로 만듬\n",
    "# 그 다음 y를 이 축에 32번 반복하면 tensor y 는 (32, 10) 이 됨.\n",
    "# 여기서 Y[i, :] == y for i in range(0, 32)가 됨.\n",
    "# 그러면 x, y 의 크기가 같으므로 더할 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현 입장에서 새로운 텐서가 만들어지면 매우 비효율적이여서 어떤 2D 텐서도 만들어지지 않는다.\n",
    "# 반복된 연산은 완전히 가상적.\n",
    "# 새로운 축을 따라 벡터가 32번 반복된다는 것으로 생각하면 됨.\n",
    "\n",
    "# 단순 구현\n",
    "def navie_add_matrix_and_vector(x,y):\n",
    "    assert len(x.shape) == 2  # 2D 넘파이 배열\n",
    "    assert len(y.shape) == 1  # y는 넘파이 배열\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a, b, ... n, n+1, ... m) 크기의 텐서와 (n, n+1, ... m) 크기의 텐서 사이에 브로드캐스팅으로 원소별 연산을 적용.\n",
    "# 이때 브로드캐스팅은 a 부터 n-1까지의 축에 자동으로 일어남.\n",
    "# 두 텐서에 브로드캐스팅으로 원소별 maximum 연산을 적용하는 예.\n",
    "\n",
    "import numpy as np\n",
    "x = np.random.random( (64, 3, 32, 10))  # x는 (64,3,32,10) 크기의 랜덤 텐서\n",
    "y = np.random.random( (32,10) ) # y는 (32,10) 크기의 랜덤 텐서\n",
    "z = np.maximum(x,y) #출력 z 크기는 x와 동일하게 (64,3,32,10) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 점곱\n",
    "# 텐서 곱셈이라고도 부르는 (원소별 곱셈과 혼동하지 마세요). 점곱 연산은 가장 널리 사용되고 유용한 텐서 연산\n",
    "# - 원소별 연산과 반대로 입력 텐서의 원소들을 결합시킨다.\n",
    "# numpy, keras, Tensorflow에서 원소별 곱셈은 * 연산자 사용. Tensorflow에서는 dot 연산자가 다르지만 numpy, keras는 점곱 연산에 보편적인 dot 연산자를 사용\n",
    "\n",
    "import numpy as np\n",
    "z = np.dot(x,y)\n",
    "z = x * y\n",
    "\n",
    "# 점곱 연산은 2개의 벡터 x,y 의 점곱은 아래와 같음\n",
    "\n",
    "def naive_vector_dot(x,y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "\n",
    "# 두 벡터의 점곱은 스칼라, 원소 개수가 같은 벡터끼리 점곱이 가능함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2799165af89f6601175a680ebfc1dbe06732e477f7b817379fe26488ea1526c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('workspace')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
