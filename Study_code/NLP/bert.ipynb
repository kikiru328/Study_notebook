{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1SnwOX2Twmx6jch2_zn-1b4mJ9-dGA_pX","authorship_tag":"ABX9TyP4cJP1qxyzoXim7byRmim5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c45bb55676174f818f964f8dc745bc54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8936e8b717564571ab4074053fc3ac6f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa22bf181c674584bed63a1bfebc1bfb","IPY_MODEL_f423a9f8b455451dba87cbe686bce2a2","IPY_MODEL_9b99364f8be04db196ca0ac4dd49ead9"]}},"8936e8b717564571ab4074053fc3ac6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa22bf181c674584bed63a1bfebc1bfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_10838cd8a00c422db96575672785eedf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_50d6a2b1f1844b34a5e60e65b3b1ac49"}},"f423a9f8b455451dba87cbe686bce2a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_684f4063441a4499b54d6995c47e59df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43acf2b04251451b80f6c2f29aa227bc"}},"9b99364f8be04db196ca0ac4dd49ead9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d0d158a70dc40649584f4e718c38b4a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 972k/972k [00:00&lt;00:00, 1.74MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8d724e9dd1854906a6ecd1f3cc1b370b"}},"10838cd8a00c422db96575672785eedf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"50d6a2b1f1844b34a5e60e65b3b1ac49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"684f4063441a4499b54d6995c47e59df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"43acf2b04251451b80f6c2f29aa227bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d0d158a70dc40649584f4e718c38b4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8d724e9dd1854906a6ecd1f3cc1b370b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1a74c707d774c6795accc688b160e02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bae9f85a5d3d474cac8c78c92edd4c45","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f2730accfd59484c95f77060aa82b61d","IPY_MODEL_9cfd95d4cc1e40a4bb7b5da70ef0207a","IPY_MODEL_f2fe1f088d304951b361e421372ab4ea"]}},"bae9f85a5d3d474cac8c78c92edd4c45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2730accfd59484c95f77060aa82b61d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_606fc0467d2b4088824eaf42332cea3e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a829158ea87465e9da2dd7747c8c7d0"}},"9cfd95d4cc1e40a4bb7b5da70ef0207a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5aa16cc4d30a4afd9a0f75e5444631f2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b705ee900e7f4c76b93d6f767a1f4dfe"}},"f2fe1f088d304951b361e421372ab4ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_891cd9a2b20e466ebc865a52a332fad2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 1.16kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_576ab7f0cf77413aa9665fa6c44361f2"}},"606fc0467d2b4088824eaf42332cea3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a829158ea87465e9da2dd7747c8c7d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5aa16cc4d30a4afd9a0f75e5444631f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b705ee900e7f4c76b93d6f767a1f4dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"891cd9a2b20e466ebc865a52a332fad2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"576ab7f0cf77413aa9665fa6c44361f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b1bea8640164c2fae06dc64b7ddeaf0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b1c27416a7fc4c3e860f5a67b4af2c72","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8cc2e0a06f2c4bc3b56ee37a3657e90f","IPY_MODEL_4f5afc50ca4940f8abc59e28a8d63853","IPY_MODEL_1b0e702db69b47ba98d548fad7e4dd7e"]}},"b1c27416a7fc4c3e860f5a67b4af2c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8cc2e0a06f2c4bc3b56ee37a3657e90f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_caaf49b465854b22bac6f06ac4a2bf6a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f7bb23616d4472abaed09122e7d45d7"}},"4f5afc50ca4940f8abc59e28a8d63853":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c6c72cbb88d84b00ad542007f092e8eb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1961828,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1961828,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5556b2e6d7aa4368bafd8522f50be0fe"}},"1b0e702db69b47ba98d548fad7e4dd7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fec9cf5fbaf64588a0aab6cfbf14d025","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.87M/1.87M [00:00&lt;00:00, 1.64MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c4d0ad3d4f44e68be0e05892d79301e"}},"caaf49b465854b22bac6f06ac4a2bf6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f7bb23616d4472abaed09122e7d45d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6c72cbb88d84b00ad542007f092e8eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5556b2e6d7aa4368bafd8522f50be0fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fec9cf5fbaf64588a0aab6cfbf14d025":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c4d0ad3d4f44e68be0e05892d79301e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"573d2e33436945c3aef70e2e2d87d21b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8bc84197210b404daf44379860d32732","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_323b1c2686e04075a36ab5ba5feab8b9","IPY_MODEL_0afbd10fcffa4edd951f415c2aff1e94","IPY_MODEL_3e15b4d0dfb243129350134316190144"]}},"8bc84197210b404daf44379860d32732":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"323b1c2686e04075a36ab5ba5feab8b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9142a9bfe49840ebba9ecb9603a09cfd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_331b3b7bad3149e685b94fc6e09ff78c"}},"0afbd10fcffa4edd951f415c2aff1e94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b604043d3c60454c8a52c083957f457d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0a6eb112d764143a3a2a37ddfe52c9c"}},"3e15b4d0dfb243129350134316190144":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0af09f8fe4b346988cbf18931f1efa1d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 23.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5ceab82fb9345b3a3bdadd92855acb0"}},"9142a9bfe49840ebba9ecb9603a09cfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"331b3b7bad3149e685b94fc6e09ff78c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b604043d3c60454c8a52c083957f457d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c0a6eb112d764143a3a2a37ddfe52c9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0af09f8fe4b346988cbf18931f1efa1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f5ceab82fb9345b3a3bdadd92855acb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"80nIjT6KSjav"},"source":["https://huggingface.co/transformers/\n","\n","- HuggingFace는 자연어 처리 인공지능 모델에서, BERT 모델 같은 트랜스포머 모델들을 쉽게 다룰 수 있게 해주는 패키지입니다.\n","- 기본적으로 pytorch 기반으로 만들어져 있지만, 텐서플로우 2.0에서도 본 패키지 사용 가능합니다.\n","- 텐서플로우 2.0은 기존 케라스를 포함하고 있기 때문에, 기존 텐서플로우나 케라스에 익숙하신 분들이 쉽게 사용할 수 있습니다.\n","- 텐서플로우 2.0 기반의 huggingface 사용 방법을 네이버 영화 긍부정 분석을 실슴하면서 배워 보도록 하겠습니다.\n","\n","* 인스톨\n","huggingface 패키지를 Colab에 설치합니다.\n","\n","- 허깅페이스는 트랜스포머를 기반으로 하는 다양한 모델 (transformer.models)과 학습 스크립트(transformer.Trainer)를 구현해 놓은 모듈이다. \n","- 원래는 파이토치로 layer, model등을 선언해주고 학습 스크립트도 전부 구현해야 하지만, 허깅 페이스를 사용하면 이런 수고를 덜 수 있다.\n","- 정리하면 허깅페이스라는 회사가 만든 transformers 패키지가 있고, 일반적인 파이토치 구현체의 layer.py, model.py이 transfomer.models 에 train.py가 transformer.Trainer에 대응된다"]},{"cell_type":"code","metadata":{"id":"QvfKaPNqUgi0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635990420663,"user_tz":-540,"elapsed":5209,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"83d5cfd2-b657-4a8f-bb60-a08a31456e55"},"source":["!pip install transformers\n","!pip install sentencepiece"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"pgIDx1lMVfk1","executionInfo":{"status":"ok","timestamp":1635990467934,"user_tz":-540,"elapsed":293,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from transformers import TFBertModel\n","import json\n","from tqdm import tqdm\n","import os"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uR5IawbWI7g","executionInfo":{"status":"ok","timestamp":1635902000263,"user_tz":-540,"elapsed":15188,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"ca627f41-2349-4796-e1eb-81791d56b8fc"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","metadata":{"id":"UMyhOz-JWm0V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635984942656,"user_tz":-540,"elapsed":5768,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"f8f1e4b5-0363-4dd8-82bf-c51d118439d2"},"source":["!git clone https://github.com/e9t/nsmc.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 23.12 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApqINIAuXWRW","executionInfo":{"status":"ok","timestamp":1635984942658,"user_tz":-540,"elapsed":19,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"c749f408-563a-4359-a28a-77cc2d5e8c05"},"source":["os.listdir('nsmc')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ratings_train.txt',\n"," 'ratings.txt',\n"," 'ratings_test.txt',\n"," 'raw',\n"," 'README.md',\n"," '.git',\n"," 'synopses.json',\n"," 'code']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"xKP5eNUCXYmg","executionInfo":{"status":"ok","timestamp":1635984943061,"user_tz":-540,"elapsed":414,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"a042f719-e0c0-4749-f789-9cea68891ae9"},"source":["train = pd.read_table('nsmc/' + 'ratings_train.txt')\n","test = pd.read_table('nsmc/' + 'ratings_test.txt')\n","train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"AbjdegBTXtJ5","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["c45bb55676174f818f964f8dc745bc54","8936e8b717564571ab4074053fc3ac6f","aa22bf181c674584bed63a1bfebc1bfb","f423a9f8b455451dba87cbe686bce2a2","9b99364f8be04db196ca0ac4dd49ead9","10838cd8a00c422db96575672785eedf","50d6a2b1f1844b34a5e60e65b3b1ac49","684f4063441a4499b54d6995c47e59df","43acf2b04251451b80f6c2f29aa227bc","2d0d158a70dc40649584f4e718c38b4a","8d724e9dd1854906a6ecd1f3cc1b370b","c1a74c707d774c6795accc688b160e02","bae9f85a5d3d474cac8c78c92edd4c45","f2730accfd59484c95f77060aa82b61d","9cfd95d4cc1e40a4bb7b5da70ef0207a","f2fe1f088d304951b361e421372ab4ea","606fc0467d2b4088824eaf42332cea3e","5a829158ea87465e9da2dd7747c8c7d0","5aa16cc4d30a4afd9a0f75e5444631f2","b705ee900e7f4c76b93d6f767a1f4dfe","891cd9a2b20e466ebc865a52a332fad2","576ab7f0cf77413aa9665fa6c44361f2","9b1bea8640164c2fae06dc64b7ddeaf0","b1c27416a7fc4c3e860f5a67b4af2c72","8cc2e0a06f2c4bc3b56ee37a3657e90f","4f5afc50ca4940f8abc59e28a8d63853","1b0e702db69b47ba98d548fad7e4dd7e","caaf49b465854b22bac6f06ac4a2bf6a","6f7bb23616d4472abaed09122e7d45d7","c6c72cbb88d84b00ad542007f092e8eb","5556b2e6d7aa4368bafd8522f50be0fe","fec9cf5fbaf64588a0aab6cfbf14d025","7c4d0ad3d4f44e68be0e05892d79301e","573d2e33436945c3aef70e2e2d87d21b","8bc84197210b404daf44379860d32732","323b1c2686e04075a36ab5ba5feab8b9","0afbd10fcffa4edd951f415c2aff1e94","3e15b4d0dfb243129350134316190144","9142a9bfe49840ebba9ecb9603a09cfd","331b3b7bad3149e685b94fc6e09ff78c","b604043d3c60454c8a52c083957f457d","c0a6eb112d764143a3a2a37ddfe52c9c","0af09f8fe4b346988cbf18931f1efa1d","f5ceab82fb9345b3a3bdadd92855acb0"]},"executionInfo":{"status":"ok","timestamp":1635984945281,"user_tz":-540,"elapsed":2228,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"f135eda1-a7d4-40e9-845f-e9d02affe904"},"source":["# bert input\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c45bb55676174f818f964f8dc745bc54","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1a74c707d774c6795accc688b160e02","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b1bea8640164c2fae06dc64b7ddeaf0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"573d2e33436945c3aef70e2e2d87d21b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shyrh4OEX5Qk","executionInfo":{"status":"ok","timestamp":1635984945283,"user_tz":-540,"elapsed":36,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"80ac0e58-66bd-4354-8354-e29b7d826a07"},"source":["tokenizer.encode('보는내내 그대로 들어맞는 예측 카리스마 없는 악역')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[101,\n"," 9356,\n"," 11018,\n"," 31605,\n"," 31605,\n"," 110589,\n"," 71568,\n"," 118913,\n"," 11018,\n"," 9576,\n"," 119281,\n"," 9786,\n"," 79940,\n"," 23811,\n"," 40364,\n"," 9520,\n"," 23160,\n"," 102]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SL0n1oXQYQKc","executionInfo":{"status":"ok","timestamp":1635984945284,"user_tz":-540,"elapsed":31,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"a11ea7af-ed64-42e1-8864-bbd22e939bd7"},"source":["tokenizer.tokenize('보는내내 그대로 들어맞는 예측 카리스마 없는 악역')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['보',\n"," '##는',\n"," '##내',\n"," '##내',\n"," '그대로',\n"," '들어',\n"," '##맞',\n"," '##는',\n"," '예',\n"," '##측',\n"," '카',\n"," '##리스',\n"," '##마',\n"," '없는',\n"," '악',\n"," '##역']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZn38EdhYkGk","executionInfo":{"status":"ok","timestamp":1635984945285,"user_tz":-540,"elapsed":25,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"6865736c-b107-4f00-8a69-2a3de0735875"},"source":["print( tokenizer.encode('전율을 일으키는 영화. 다시 보고 싶은 영화', max_length = 129 ,pad_to_max_length = True))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["[101, 9665, 119183, 10622, 9641, 119185, 66815, 42428, 119, 25805, 98199, 9495, 10892, 42428, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1jHHs7LZF6t","executionInfo":{"status":"ok","timestamp":1635984945286,"user_tz":-540,"elapsed":21,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"3e6bf347-aa23-42bb-8d42-a19731a759d5"},"source":["# mask 인풋\n","valid_num = len(tokenizer.encode('전율을 일으키는 영화. 다시 보고 싶은 영화'))\n","print(valid_num * [1] + (128 -valid_num) * [0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZawCqrmVZxbU"},"source":["# 네이버 영화 평가 무장들을 버트 인풋으로 변환"]},{"cell_type":"code","metadata":{"id":"Dh69HyOWaXRo","executionInfo":{"status":"ok","timestamp":1635990672728,"user_tz":-540,"elapsed":301,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["def convert_data(data_df):\n","  global tokenizer\n","\n","  SEQ_LEN= 128  # bert 인풋의 길이 \n","\n","  tokens, masks, segments, targets = [],[],[],[]\n","\n","  for i in tqdm(range(len(data_df))):\n","    token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length= SEQ_LEN, truncation=True,padding='max_length')\n","\n","    num_zeros= token.count(0)\n","    mask = [1]* (SEQ_LEN-num_zeros) + [0]*num_zeros\n","\n","    segment = [0] *SEQ_LEN\n","\n","    tokens.append(token)\n","    masks.append(mask)\n","    segments.append(segment)\n","\n","    targets.append(data_df[LABEL_COLUMN][i])\n","\n","  tokens= np.array(tokens)\n","  masks= np.array(masks)\n","  segments= np.array(segments)\n","  targets= np.array(targets)\n","\n","  return  [tokens,masks, segments], targets\n"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqrAChjPckhV","executionInfo":{"status":"ok","timestamp":1635990709833,"user_tz":-540,"elapsed":36805,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"ca4ddcdc-054f-4b74-fcb1-4ff67c9a536b"},"source":["def load_data(pandas_dataframe):\n","  data_df = pandas_dataframe\n","  data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","  data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n","  data_x, data_y = convert_data(data_df)\n","  return data_x, data_y\n","\n","\n","SEQ_LEN= 128\n","BATCH_SIZE = 20\n","DATA_COLUMN = 'document'\n","LABEL_COLUMN= 'label'\n","\n","train_x, train_y= load_data(train)\n"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 150000/150000 [00:31<00:00, 4708.05it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2U282uGpde64","executionInfo":{"status":"ok","timestamp":1635990721504,"user_tz":-540,"elapsed":11761,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"b53b6d39-39b9-410e-d25a-213e44befc67"},"source":["test_x, test_y = load_data(test)"],"execution_count":72,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 50000/50000 [00:10<00:00, 4918.65it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sjWSJmnehan","executionInfo":{"status":"ok","timestamp":1635990778821,"user_tz":-540,"elapsed":347,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"7c823821-a384-44c3-f2e0-52909212629d"},"source":["test_y"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 0, 0])"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"MJbYxSlweiqd"},"source":["#### 버트를 활용한 감성분석 모델 만들기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"id":"EoT0tlFCerer","executionInfo":{"status":"error","timestamp":1635990781193,"user_tz":-540,"elapsed":62,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"c0007af0-da36-4648-e72a-ff13251126ac"},"source":["# TPU 객체지정\n","TPU = True\n","if TPU :\n","    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","    tf.config.experimental_connect_to_cluster(resolver)\n","    tf.tpu.experimental.initialize_tpu_system(resolver)\n","else:\n","    pass"],"execution_count":74,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-c18d10283d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"]}]},{"cell_type":"code","metadata":{"id":"2d-8SDldfHee","executionInfo":{"status":"aborted","timestamp":1635990781181,"user_tz":-540,"elapsed":38,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["# Rectified Adam 옵티마이저 사용\n","!pip install tensorflow_addons\n","import tensorflow_addons as tfa\n","opt = tfa.optimizers.RectifiedAdam(\n","    learning_rate = 1.0e-5, weight_decay = 0.0025, warmup_proportion = 0.05\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEOqo5bmUhep","executionInfo":{"status":"aborted","timestamp":1635990781189,"user_tz":-540,"elapsed":45,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["def create_sentiment_bert():\n","  model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n","  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n","  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n","  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n","  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n","\n","  bert_outputs = bert_outputs[1]\n","  sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)\n","  sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n","\n","  sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n","  return sentiment_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BjaKeTorWlP4","executionInfo":{"status":"aborted","timestamp":1635990781192,"user_tz":-540,"elapsed":46,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["# TPU 실행시\n","if TPU:\n","    strategy  =  tf. distribute. experimental. TPUStrategy( resolver )\n","    with strategy.scope():\n","        sentiment_model = create_sentiment_bert()\n","    sentiment_model.fit(train_x, train_y, epochs = 4, shuffle = True, batch_size = 100, validation_data = ( test_x, test_y) )\n","else:\n","    sentiment_model = create_sentiment_bert()\n","    sentiment_model.fit(train_x, train_y, epochs = 4, shuffle = True, batch_size = 100, validation_data = ( test_x, test_y) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73UUrum1XeQT"},"source":["한글 데이터를 분석하려면, 100개가 넘는 언얻에 대해 훈련된 버트를 사용해야 합니다.\n","이번에는 한국어 데이터로 훈련되었고, SKT에서 만든 koBERT를 사용하도록 하겠습니다.\n","모델을 로드하기에 앞서, 토크나이저를 불러오도록 하겠습니다.\n","huggingface에서는 아주 쉽게 토크나이저를 불러올 수 있습니다.\n","\n","https://github.com/monologg/KoBERT-NER\n","\n","How to use KoBERT on Huggingface Transformers Library\n","- 기존의 KoBERT를 transformers라이브러리에서 곧바로 사용할 수 있도록 맞췄습니다.\n","- transformers v2.2.2부터 개인이 만든 모델을 transformers를 통해 직접 업로드/다운로드하여 사용할 수 있습니다\n","- Tokenizer를 사용하려면 tokenization_kobert.py 에서 KoBertTokenizer를 임포트 해야합니다.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hhw3qZgjf-Lw","executionInfo":{"status":"ok","timestamp":1635990785941,"user_tz":-540,"elapsed":10,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"b767327b-612e-4fbf-d7ad-89f3165b4a66"},"source":["# 네이버 영화 감성분석 데이터 다운로드\n","!git clone https://github.com/e9t/nsmc.git"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'nsmc' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPzInUM0f-X7","executionInfo":{"status":"ok","timestamp":1635990787012,"user_tz":-540,"elapsed":386,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"a67b248f-4b67-4307-b040-595f9bd3e9f7"},"source":["import os\n","os.listdir('nsmc')"],"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ratings_train.txt',\n"," '.git',\n"," 'synopses.json',\n"," 'ratings.txt',\n"," 'ratings_test.txt',\n"," 'raw',\n"," 'README.md',\n"," 'code']"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"i8tK7jZwf_-f","executionInfo":{"status":"ok","timestamp":1635990787017,"user_tz":-540,"elapsed":32,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["import pandas as pd\n","train = pd.read_table('nsmc/' + 'ratings_train.txt')\n","test = pd.read_table('nsmc/' + 'ratings_test.txt')"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"WeX-NM_xgJ-h","executionInfo":{"status":"ok","timestamp":1635990787034,"user_tz":-540,"elapsed":49,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"e8fef6ef-2f7a-4bb6-abb1-a64ae231ef16"},"source":["train.head()"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":112},"id":"6pyEzYymgN8z","executionInfo":{"status":"ok","timestamp":1635990968091,"user_tz":-540,"elapsed":181104,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"c4a04f55-9db5-4a24-c3c2-28485f797c2e"},"source":["# tokenization_kobert.py upload\n","from google.colab import files\n","files.upload()"],"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-653028d8-81ec-4a63-85a3-bce04b38bc9c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-653028d8-81ec-4a63-85a3-bce04b38bc9c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving tokenization_kobert.py to tokenization_kobert (2).py\n"]},{"output_type":"execute_result","data":{"text/plain":["{'tokenization_kobert.py': b'# coding=utf-8\\n# Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team and Jangwon Park\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \"AS IS\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n\"\"\" Tokenization classes for KoBert model.\"\"\"\\n\\n\\nimport logging\\nimport os\\nimport unicodedata\\nfrom shutil import copyfile\\n\\nfrom transformers import PreTrainedTokenizer\\n\\n\\nlogger = logging.getLogger(__name__)\\n\\nVOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\\n                     \"vocab_txt\": \"vocab.txt\"}\\n\\nPRETRAINED_VOCAB_FILES_MAP = {\\n    \"vocab_file\": {\\n        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\\n        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\\n        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\\n    },\\n    \"vocab_txt\": {\\n        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\\n        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\\n        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\\n    }\\n}\\n\\nPRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\\n    \"monologg/kobert\": 512,\\n    \"monologg/kobert-lm\": 512,\\n    \"monologg/distilkobert\": 512\\n}\\n\\nPRETRAINED_INIT_CONFIGURATION = {\\n    \"monologg/kobert\": {\"do_lower_case\": False},\\n    \"monologg/kobert-lm\": {\"do_lower_case\": False},\\n    \"monologg/distilkobert\": {\"do_lower_case\": False}\\n}\\n\\nSPIECE_UNDERLINE = u\\'\\xe2\\x96\\x81\\'\\n\\n\\nclass KoBertTokenizer(PreTrainedTokenizer):\\n    \"\"\"\\n        SentencePiece based tokenizer. Peculiarities:\\n            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\\n    \"\"\"\\n    vocab_files_names = VOCAB_FILES_NAMES\\n    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\\n    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\\n    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\\n\\n    def __init__(\\n            self,\\n            vocab_file,\\n            vocab_txt,\\n            do_lower_case=False,\\n            remove_space=True,\\n            keep_accents=False,\\n            unk_token=\"[UNK]\",\\n            sep_token=\"[SEP]\",\\n            pad_token=\"[PAD]\",\\n            cls_token=\"[CLS]\",\\n            mask_token=\"[MASK]\",\\n            **kwargs):\\n        super().__init__(\\n            unk_token=unk_token,\\n            sep_token=sep_token,\\n            pad_token=pad_token,\\n            cls_token=cls_token,\\n            mask_token=mask_token,\\n            **kwargs\\n        )\\n\\n        # Build vocab\\n        self.token2idx = dict()\\n        self.idx2token = []\\n        with open(vocab_txt, \\'r\\', encoding=\\'utf-8\\') as f:\\n            for idx, token in enumerate(f):\\n                token = token.strip()\\n                self.token2idx[token] = idx\\n                self.idx2token.append(token)\\n\\n        try:\\n            import sentencepiece as spm\\n        except ImportError:\\n            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\\n                           \"pip install sentencepiece\")\\n\\n        self.do_lower_case = do_lower_case\\n        self.remove_space = remove_space\\n        self.keep_accents = keep_accents\\n        self.vocab_file = vocab_file\\n        self.vocab_txt = vocab_txt\\n\\n        self.sp_model = spm.SentencePieceProcessor()\\n        self.sp_model.Load(vocab_file)\\n\\n    @property\\n    def vocab_size(self):\\n        return len(self.idx2token)\\n\\n    def get_vocab(self):\\n        return dict(self.token2idx, **self.added_tokens_encoder)\\n\\n    def __getstate__(self):\\n        state = self.__dict__.copy()\\n        state[\"sp_model\"] = None\\n        return state\\n\\n    def __setstate__(self, d):\\n        self.__dict__ = d\\n        try:\\n            import sentencepiece as spm\\n        except ImportError:\\n            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\\n                           \"pip install sentencepiece\")\\n        self.sp_model = spm.SentencePieceProcessor()\\n        self.sp_model.Load(self.vocab_file)\\n\\n    def preprocess_text(self, inputs):\\n        if self.remove_space:\\n            outputs = \" \".join(inputs.strip().split())\\n        else:\\n            outputs = inputs\\n        outputs = outputs.replace(\"``\", \\'\"\\').replace(\"\\'\\'\", \\'\"\\')\\n\\n        if not self.keep_accents:\\n            outputs = unicodedata.normalize(\\'NFKD\\', outputs)\\n            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\\n        if self.do_lower_case:\\n            outputs = outputs.lower()\\n\\n        return outputs\\n\\n    def _tokenize(self, text, return_unicode=True, sample=False):\\n        \"\"\" Tokenize a string. \"\"\"\\n        text = self.preprocess_text(text)\\n\\n        if not sample:\\n            pieces = self.sp_model.EncodeAsPieces(text)\\n        else:\\n            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\\n        new_pieces = []\\n        for piece in pieces:\\n            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\\n                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\\n                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\\n                    if len(cur_pieces[0]) == 1:\\n                        cur_pieces = cur_pieces[1:]\\n                    else:\\n                        cur_pieces[0] = cur_pieces[0][1:]\\n                cur_pieces.append(piece[-1])\\n                new_pieces.extend(cur_pieces)\\n            else:\\n                new_pieces.append(piece)\\n\\n        return new_pieces\\n\\n    def _convert_token_to_id(self, token):\\n        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\\n        return self.token2idx.get(token, self.token2idx[self.unk_token])\\n\\n    def _convert_id_to_token(self, index, return_unicode=True):\\n        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\\n        return self.idx2token[index]\\n\\n    def convert_tokens_to_string(self, tokens):\\n        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\\n        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\\n        return out_string\\n\\n    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\\n        \"\"\"\\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\\n        by concatenating and adding special tokens.\\n        A KoBERT sequence has the following format:\\n            single sequence: [CLS] X [SEP]\\n            pair of sequences: [CLS] A [SEP] B [SEP]\\n        \"\"\"\\n        if token_ids_1 is None:\\n            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\\n        cls = [self.cls_token_id]\\n        sep = [self.sep_token_id]\\n        return cls + token_ids_0 + sep + token_ids_1 + sep\\n\\n    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\\n        \"\"\"\\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\\n        Args:\\n            token_ids_0: list of ids (must not contain special tokens)\\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\\n                for sequence pairs\\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\\n                special tokens for the model\\n        Returns:\\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\\n        \"\"\"\\n\\n        if already_has_special_tokens:\\n            if token_ids_1 is not None:\\n                raise ValueError(\\n                    \"You should not supply a second sequence if the provided sequence of \"\\n                    \"ids is already formated with special tokens for the model.\"\\n                )\\n            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\\n\\n        if token_ids_1 is not None:\\n            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\\n        return [1] + ([0] * len(token_ids_0)) + [1]\\n\\n    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\\n        \"\"\"\\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\\n        A KoBERT sequence pair mask has the following format:\\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\\n        | first sequence    | second sequence\\n        if token_ids_1 is None, only returns the first portion of the mask (0\\'s).\\n        \"\"\"\\n        sep = [self.sep_token_id]\\n        cls = [self.cls_token_id]\\n        if token_ids_1 is None:\\n            return len(cls + token_ids_0 + sep) * [0]\\n        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\\n\\n    def save_vocabulary(self, save_directory):\\n        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\\n            to a directory.\\n        \"\"\"\\n        if not os.path.isdir(save_directory):\\n            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\\n            return\\n\\n        # 1. Save sentencepiece model\\n        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\\n\\n        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\\n            copyfile(self.vocab_file, out_vocab_model)\\n\\n        # 2. Save vocab.txt\\n        index = 0\\n        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\\n        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\\n            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\\n                if index != token_index:\\n                    logger.warning(\\n                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\\n                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\\n                    )\\n                    index = token_index\\n                writer.write(token + \"\\\\n\")\\n                index += 1\\n\\n        return out_vocab_model, out_vocab_txt\\n'}"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bO6CLMTagogn","executionInfo":{"status":"ok","timestamp":1635990970506,"user_tz":-540,"elapsed":2421,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"fc2ab989-22bb-4f84-ba0d-9162f1fc676e"},"source":["from tokenization_kobert import KoBertTokenizer\n","tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"],"execution_count":80,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'KoBertTokenizer'.\n"]}]},{"cell_type":"code","metadata":{"id":"Z_68venSk2Ru","executionInfo":{"status":"ok","timestamp":1635990970507,"user_tz":-540,"elapsed":12,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["from tqdm import tqdm\n","import numpy as np"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLWNFO3Qiuvl","executionInfo":{"status":"ok","timestamp":1635990970507,"user_tz":-540,"elapsed":12,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["def convert_data(data_df):\n","    global tokenizer\n","    SEQ_LEN = 64\n","\n","    tokens, masks, segments, targets = [], [], [], []\n","\n","    for i in tqdm (range( len( data_df ))):\n","        token = tokenizer.encode (data_df[DATA_COLUMN][i], truncation = True, padding = 'max_length', max_length = SEQ_LEN)\n","        num_zeros = token.count(0)\n","        mask = [1] * (SEQ_LEN-num_zeros) + [0] * num_zeros\n","\n","        segment = [0] * SEQ_LEN\n","        tokens.append(token)\n","        masks.append(mask)\n","        segments.append(segment)\n","\n","        targets.append(data_df[LABEL_COLUMN][i])\n","    \n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    targets = np.array(targets)\n","\n","    return [tokens, masks, segments], targets"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPiQzOhbkWny","executionInfo":{"status":"ok","timestamp":1635990970507,"user_tz":-540,"elapsed":11,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":["def load_data(pandas_dataframe):\n","    data_df = pandas_dataframe\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n","    data_x, data_y = convert_data(data_df)\n","    return data_x, data_y"],"execution_count":83,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoaloDJXkrIc","executionInfo":{"status":"ok","timestamp":1635991003856,"user_tz":-540,"elapsed":33359,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"0d1f5c07-5e33-4e0b-df19-2be1fd6575ee"},"source":["SEQ_LEN = 64\n","BATCH_SIZE = 32\n","DATA_COLUMN = 'document'\n","LABEL_COLUMN = 'label'\n","\n","train_x, train_y = load_data(train)"],"execution_count":84,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 150000/150000 [00:30<00:00, 4839.15it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"nmhOIflDmX45"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxbXtl9Qk0jy","executionInfo":{"status":"ok","timestamp":1635991007039,"user_tz":-540,"elapsed":3199,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"6d0d9988-2ea6-4d71-9ab7-d8f525798f6d"},"source":["\n","model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n","# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n","token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n","mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n","segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n","# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n","bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"],"execution_count":85,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","metadata":{"id":"uOf-q4jrmKA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635991007039,"user_tz":-540,"elapsed":7,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"3dd48916-b21a-44fb-acad-f51a0d053137"},"source":["bert_outputs = bert_outputs[1]\n","bert_outputs.shape"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([None, 768])"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"bXE4x1ENm3o6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635991009621,"user_tz":-540,"elapsed":2586,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"a83cf4f4-0d08-4a61-8213-9a6765a4918f"},"source":["!pip install tensorflow_addons\n","import tensorflow_addons as tfa\n","# 총 batch size * 4 epoch = 2344 * 4\n","opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*2, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)"],"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwtf_5ArofIR","executionInfo":{"status":"ok","timestamp":1635991009622,"user_tz":-540,"elapsed":9,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"ed1dce61-7e37-458e-ba0d-22bec2d1a267"},"source":["sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n","sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\n","sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n","sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n","\n","sentiment_model.summary()"],"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_word_ids (InputLayer)     [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","input_masks (InputLayer)        [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","input_segment (InputLayer)      [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model_2 (TFBertModel)   TFBaseModelOutputWit 92186880    input_word_ids[0][0]             \n","                                                                 input_masks[0][0]                \n","                                                                 input_segment[0][0]              \n","__________________________________________________________________________________________________\n","dropout_112 (Dropout)           (None, 768)          0           tf_bert_model_2[0][1]            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            769         dropout_112[0][0]                \n","==================================================================================================\n","Total params: 92,187,649\n","Trainable params: 92,187,649\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"lxN4qLJzowu0","executionInfo":{"status":"error","timestamp":1635992264077,"user_tz":-540,"elapsed":1254460,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}},"outputId":"c1b476df-8097-43ac-ebc8-d55b26f078dd"},"source":["sentiment_model.fit(train_x, train_y, epochs=2, shuffle=True, batch_size=64, validation_data=(test_x, test_y))"],"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2344/2344 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.7978"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-07435b3085be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1227\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1330 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1320 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1313 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1267 test_step\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:269 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 64), found shape=(None, 128)\n"]}]},{"cell_type":"code","metadata":{"id":"Zx44vh-to5Oe","executionInfo":{"status":"aborted","timestamp":1635992264073,"user_tz":-540,"elapsed":32,"user":{"displayName":"김광훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiqW8UtITeK-JGes7Q30DXICUCws1LqWQSTAndOA=s64","userId":"07437956116695752254"}}},"source":[""],"execution_count":null,"outputs":[]}]}